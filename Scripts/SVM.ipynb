{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de8b02a-3669-4656-934b-b9aed3503cf8",
   "metadata": {},
   "source": [
    "## Partie I: Preparation des données (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccba860-7152-4ac8-9e6c-0d05d3a489a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO #permet de stocker en mémoire\n",
    "from zipfile import ZipFile\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "url2019 = \"https://www.insee.fr/fr/statistiques/fichier/4809583/fd_eec19_csv.zip\" #enquete 2019\n",
    "url2020=\"https://www.insee.fr/fr/statistiques/fichier/5393560/fd_eec20_csv.zip\" #enquête 2020 en exemple\n",
    "\n",
    "# Télécharge le fichier ZIP\n",
    "requete = requests.get(url2019)\n",
    "zip_df = ZipFile(BytesIO(requete.content)) #créer un fichier ZIP\n",
    "\n",
    "# Extraire le fichier CSV du ZIP\n",
    "with zip_df.open(zip_df.namelist()[0]) as extrait:\n",
    "    EEC_2019 = pd.read_csv(extrait, delimiter=\";\") # Lire le fichier CSV avec pandas\n",
    "\n",
    "# Télécharge le fichier ZIP\n",
    "requete = requests.get(url2020)\n",
    "zip_df = ZipFile(BytesIO(requete.content)) #créer un fichier ZIP\n",
    "\n",
    "# Extraire le fichier CSV du ZIP\n",
    "with zip_df.open(zip_df.namelist()[0]) as extrait:\n",
    "    EEC_2020 = pd.read_csv(extrait, delimiter=\";\") # Lire le fichier CSV avec pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef38744-9012-49cc-9694-a086980b25e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACTEU', 'ANNEE', 'TRIM', 'AGE3', 'AGE5', 'CATAU2010R', 'COURED', 'CSTOT', 'CSTOTR', 'CSTOTPRM', 'DIP11', 'ENFRED', 'METRODOM', 'NFRRED', 'SEXE', 'TYPMEN7']\n",
      "(416298, 16)\n",
      "(412028, 16)\n",
      "(412028, 133)\n"
     ]
    }
   ],
   "source": [
    "# On choisit un set de variables qui ne comprend que données sociodémographiques, géographiques associées à l'individu\n",
    "# et au ménage étudié + qui soit disponible sur les deux années étudiées\n",
    "\n",
    "# Var d'interet -> ACTEU\n",
    "\n",
    "# Var explicatives  à inclure dans le modèle -> AGE3 ;  AGE5 ; ANNEE ;TRIM ;  CATAU2010R ; COURED ; CSTOT (pour avoir actifs et inactifs) ;CSTOTR ;\n",
    "# CSTOTPRM ; DIP11; ENFRED ; METRODOM ; NFRRED ; SEXE ; TYPMEN7 \n",
    "\n",
    "# USE? -> AIDFAM , CHPUB?? (Employeur de la profession principale?), EXTRIAN? (pondération)\n",
    "\n",
    "# Meme si les variables sont colinéaires (AGE3, AGE5), on peut les garder et faire en sorte que le predicteur\n",
    "# choisisse la plus pertinente\n",
    "\n",
    "# Je pense que le problème principal vient du fait qu'on a en fait trop peu de variable, et donc rien qui ne puisse être vraiment pertinent en fait\n",
    "#c'est pour cela que les algorithmes ne trouvent rien je pense. (Alexis)\n",
    "\n",
    "list_var_selected = [\"ACTEU\",\"ANNEE\" ,\"TRIM\", \"AGE3\" ,  \"AGE5\"  , \"CATAU2010R\" ,\n",
    "\"COURED\" ,\"CSTOT\" ,\"CSTOTR\" ,\"CSTOTPRM\" , \"DIP11\",\"ENFRED\" , \"METRODOM\" , \"NFRRED\" , \"SEXE\" , \"TYPMEN7\"]\n",
    "\n",
    "EEC_2019 = EEC_2019[list_var_selected]\n",
    "EEC_2020 = EEC_2020[list_var_selected]\n",
    "\n",
    "list_var = list(EEC_2019.columns.values)\n",
    "print(list_var)\n",
    "\n",
    "#je regarde ce qu'il se passe si je ne sépare pas les trimestres, le prof avait l'air de dire que c'était pas forcément grave (Alexis)\n",
    "#EEC_2019 = EEC_2019[EEC_2019['TRIM'] ==1]\n",
    "#EEC_2020 = EEC_2020[EEC_2020['TRIM'] ==4]\n",
    "\n",
    "# Il y a très peu de valeurs manquantes dans les variables ->  dropna() drops any row that contains at least one missing value\n",
    "# On aurait aussi pu faire de l'imputation\n",
    "print(EEC_2019.shape)\n",
    "EEC_2019 = EEC_2019.dropna() \n",
    "EEC_2020 = EEC_2020.dropna() \n",
    "print(EEC_2019.shape)\n",
    "\n",
    "# Converti l'ensemble des variables catégorielles en dummies -> Réflèxe économétrique mais est ce pertinent ici? \n",
    "# Oui oui faut le faire, par contre pour les variables qui sont DEJA des dummies, c'est pas la peine, faut juste les recoder en 0 et 1\n",
    "EEC_2019 = pd.get_dummies(EEC_2019, columns=[\"AGE3\" ,  \"AGE5\"  , \"CATAU2010R\" ,\n",
    "\"CSTOT\" ,\"CSTOTR\" ,\"CSTOTPRM\" , \"DIP11\", \"NFRRED\" , \"TYPMEN7\"])\n",
    "EEC_2020 = pd.get_dummies(EEC_2020, columns=[\"AGE3\" ,  \"AGE5\"  , \"CATAU2010R\" ,\n",
    "\"CSTOT\" ,\"CSTOTR\" ,\"CSTOTPRM\" , \"DIP11\", \"NFRRED\" , \"TYPMEN7\"])\n",
    "\n",
    "#du coup je recode les variables en questions\n",
    "EEC_2019['FEMME'] = EEC_2019['SEXE'] - 1\n",
    "EEC_2020['FEMME'] = EEC_2020['SEXE'] - 1\n",
    "\n",
    "EEC_2019['COUPLE'] = 2 - EEC_2019['COURED']\n",
    "EEC_2020['COUPLE'] = 2 - EEC_2020['COURED']\n",
    "\n",
    "EEC_2019['ENFANT'] = 2 - EEC_2019['ENFRED']\n",
    "EEC_2020['ENFANT'] = 2 - EEC_2020['ENFRED']\n",
    "\n",
    "EEC_2019['DOM'] = EEC_2019['METRODOM'] - 1\n",
    "EEC_2020['DOM'] = EEC_2020['METRODOM'] - 1\n",
    "\n",
    "#et je vire les anciennes\n",
    "EEC_2019 = EEC_2019.drop(['METRODOM', 'ENFRED' , 'COURED', 'SEXE'], axis=1)\n",
    "EEC_2020 = EEC_2020.drop(['METRODOM', 'ENFRED' , 'COURED', 'SEXE'], axis=1)\n",
    "\n",
    "# 133 variables du coup\n",
    "print(EEC_2019.shape)\n",
    "\n",
    "# Gestion des outliers??? Pas nécessaire ici puisqu'on fonctionne seulement avec des variables catégorielles\n",
    "\n",
    "#si besoin de travailler sur subsample\n",
    "#EEC_2019_subsample = EEC_2019.sample(n=1000, random_state=3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e458235-6217-4cbe-80f5-d5cd808d3ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412028, 130)\n",
      "(412028,)\n",
      "[[False False True ... 0 0 0]\n",
      " [False False True ... 1 0 0]\n",
      " [False False True ... 1 0 0]\n",
      " ...\n",
      " [False True False ... 1 1 0]\n",
      " [False True False ... 1 1 0]\n",
      " [True False False ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# On construit un array contentant l'ensemble des variables explicatives (on exclut donc ACTEU/ANNEE/TRIM)\n",
    "X = np.array(EEC_2019.drop(columns=[\"ACTEU\",\"ANNEE\", \"TRIM\"]))\n",
    "\n",
    "print(X.shape)\n",
    "# Array contentant la variable expliquée\n",
    "y = np.array(EEC_2019[\"ACTEU\"])\n",
    "# convert \"Chomage\" in 1 and the other labels (here, \"Inactif\", \"Actif occupé\") into 1\n",
    "y = np.where(y==2, 1, 0)\n",
    "print(y.shape)\n",
    "\n",
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baeb637e-a210-4bb0-8ff5-20a44d84967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "# standardisation des variables explicatives,  c’est-à-dire de centrer et réduire chaque variable\n",
    "# en la divisant par sa variance  -> pas utile pour mes variables catégorielles transformées en dummies\n",
    "\n",
    "# std_scale = StandardScaler().fit(X_train)\n",
    "# X_train_scaled = std_scale.transform(X_train)\n",
    "# X_test_scaled = std_scale.transform(X_test)\n",
    "\n",
    "# La standardisation permet une convergence plus rapide des algorithmes pour des variables réelles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb28ea-826e-425a-b29e-1fbbe82f8d9a",
   "metadata": {},
   "source": [
    "## Partie II : Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8697dcf9-d388-4440-ae89-4441207bf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361594f-4143-46dc-82d5-b11503f83b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SVC est le modèle SVM permettant la classification\n",
    "#Test avec nombreuses valeurs paramètre C en vue de réalisation d'un graphique\n",
    "\n",
    "acc_train, acc_test = list(), list()\n",
    "\n",
    "C_range = np.linspace(0.1, 20, 50)\n",
    "for param in C_range:\n",
    "    clf = SVC( C=param)\n",
    "    clf.fit(X_train, y_train)\n",
    "    #on garde les scores pour le graph\n",
    "    acc_train.append(clf.score(X_train, y_train))\n",
    "    acc_test.append(clf.score(X_test, y_test))\n",
    "    #et on fait les confusions matrix\n",
    "    y_pred = clf.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f\"Confusion Matrix for C={param}\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "      \n",
    "#  ATTENTION -> Peut etre faut-il travailler avec un autre critère de performance que accuracy pour selectionner\n",
    "#  le meilleur modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410f2fb-fb38-46e7-bb1b-474bee0c1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(C_range, acc_train, label='train set', lw=4)\n",
    "plt.plot(C_range, acc_test, label='test set', lw=4)\n",
    "\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "plt.xlabel(\"C\", fontweight=\"bold\", fontsize=20)\n",
    "plt.ylabel(\"Performance\", fontweight=\"bold\", fontsize=20)\n",
    "plt.xticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.yticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d5d9c-78c1-4f00-9ad4-84ea132826e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
